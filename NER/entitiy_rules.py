import sys
import os
import re

sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from db.io import read_recruits, read_companies, read_full_region_names
import pandas as pd
from datetime import date
import logging
import spacy
from spacy.matcher import Matcher

def create_pattern_list():
    recruits = read_recruits()
    companies = read_companies()
    # recruit_tags = read_recruit_tags()
    full_regions = read_full_region_names()
    # tags = read_tags()

    # # SKILL (ì§ë¬´)
    # skill_names = recruits["name"].unique()
    # skill_patterns = [
    #     {"label": "SKILL", "pattern": skill} for skill in skill_names
    # ]

    # COMPNAY (íšŒì‚¬ëª…)
    company_names = companies["company_name"].unique()
    company_patterns = [
        {"label": "COMPANY", "pattern": company_name} for company_name in company_names
    ]

    # REGION (ì§€ì—­)
    region_names = full_regions["full_region_name"].unique()
    region_patterns = [
        {"label": "REGION", "pattern": region} for region in region_names
    ]

    # FORM (ê³ ìš© í˜•íƒœ)


    # EXPERIENCE (ê²½ë ¥)
    nlp = spacy.load("ko_core_news_sm")  # ë˜ëŠ” custom pipeline
    matcher = Matcher(nlp.vocab)

    pattern = [
        {"IS_DIGIT": True},               # ìˆ«ì: 1, 2, 3...
        {"TEXT": {"REGEX": r"ë…„(ì°¨)?"}},  # "ë…„", "ë…„ì°¨"
        {"TEXT": {"REGEX": r"ì´ìƒ|ì´í•˜"}} # "ì´ìƒ", "ì´í•˜"
    ]

    matcher.add("EXPERIENCE", [pattern])

    doc = nlp("ê²½ë ¥ 3ë…„ ì´ìƒ ë˜ëŠ” 5ë…„ì°¨ ì´ìƒë§Œ ì§€ì› ê°€ëŠ¥í•©ë‹ˆë‹¤.")
    matches = matcher(doc)

    for match_id, start, end in matches:
        span = doc[start:end]
        print("ğŸ”¹ Found:", span.text)
    
    # sample_titles = recruits["announcement_name"]
    # experience_pattern = re.compile(r"""
    #     (ì‹ ì…(ì‚¬ì›)?|ì´ˆë³´\s*ê°€ëŠ¥)                                      # ì‹ ì… ê´€ë ¨
    # | (ê²½ë ¥(ì§|ì)?(\s*ìš°ëŒ€)?|ê²½ë ¥\s*ë¬´ê´€|ë¬´ê´€)                       # ê²½ë ¥ ê´€ë ¨
    # | (ì‹ ì…\s*[Â·/]\s*ê²½ë ¥|ì‹ ì…\s+ë°\s+ê²½ë ¥|ì‹ ì…\s+ë˜ëŠ”\s+ê²½ë ¥)        # ì‹ ì…/ê²½ë ¥ ë³µí•©í˜•
    # | (\d+\s*ë…„(\s*ì°¨)?\s*(ì´ìƒ|ì´í•˜)?|\d+\s*~\s*\d+\s*ë…„(ì°¨)?)        # ì—°ì°¨ í‘œí˜„
    # | (ê²½ë ¥\s*\d+\s*ë…„(\s*ì´ìƒ)?)                                     # ì˜ˆ: ê²½ë ¥ 3ë…„ ì´ìƒ
    # | (ê²½í—˜ì|ì‹¤ë¬´\s*ê²½í—˜ì)                                          # ê²½í—˜ ê¸°ë°˜
    # """, re.VERBOSE)

    # # ìƒ˜í”Œ í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸
    # keywords = set()
    # for title in sample_titles:
    #     matches = experience_pattern.findall(title)
    #     # findallì´ group tupleì„ ë°˜í™˜í•˜ë¯€ë¡œ, í‰íƒ„í™” í›„ ë¹ˆ ë¬¸ìì—´ ì œì™¸
    #     flattened = [m for group in matches for m in group if m]
    #     keywords.update(flattened)
    
    # print("keywords : ", keywords)
    
    # exp_lists = ["ì‹ ì…","ê²½ë ¥","ê²½ë ¥ì§","ê²½ë ¥ ì‚¬ì›","ê²½ë ¥ì‚¬ì›","ê²½ë ¥ì","ê²½ë ¥ë¬´ê´€","ë…„ì´ìƒ"]
    # region_names = recruits["experience"].unique()
    # region_patterns = [
    #     {"label": "REGION", "pattern": region} for region in region_names
    # ]

    all_patterns = (
        company_patterns +
        region_patterns
    )

    # print(all_patterns)
    # ruler = nlp.add_pipe("entity_ruler", before="ner")
    # ruler.add_patterns(all_patterns)


if __name__ == "__main__":
    create_pattern_list()
